{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras fashion MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kInvwOKww4E_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9LzWooA5xDWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a496b21a-f940-48a0-8203-693307a98879"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 1s 32us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 22s 1us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 8s 2us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PM8mSMLH2p6w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLxP14Pl3Fzj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jv3IK90H5Urj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHTW6DbYxNT6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "num_epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fglaeAvwxkdK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.device(\"/:gpu0\"):\n",
        "  model = Sequential()\n",
        "  model.add(layers.normalization.BatchNormalization(input_shape=(28, 28, 1)))\n",
        "  model.add(layers.Conv2D(64, (5,5), padding='same', activation='relu', \n",
        "                          kernel_regularizer=regularizers.l2(0.01), \n",
        "                          bias_initializer = 'RandomNormal',\n",
        "                         kernel_initializer = 'random_uniform'))\n",
        "  model.add(layers.MaxPooling2D(pool_size = (2,2), padding='same'))\n",
        "  model.add(layers.Conv2D(512, (5,5), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size = (2,2), padding='same'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(units=128, activation='relu'))\n",
        "  model.add(layers.Dropout(rate=0.5))\n",
        "  model.add(layers.Dense(units=10))\n",
        "  model.add(layers.Softmax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T8VP1IIS0Meb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adam = optimizers.Adam(decay = 0.001)\n",
        "model.compile(optimizer=adam, \n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JH3LqFHj1Oxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "dc9637e7-8254-42f4-dc0a-cb0c544d2cd2"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "48000/48000 [==============================] - 19s 406us/step - loss: 0.6103 - acc: 0.7896 - val_loss: 0.3419 - val_acc: 0.8828\n",
            "Epoch 2/50\n",
            "48000/48000 [==============================] - 18s 385us/step - loss: 0.3670 - acc: 0.8758 - val_loss: 0.3053 - val_acc: 0.8952\n",
            "Epoch 3/50\n",
            "48000/48000 [==============================] - 18s 385us/step - loss: 0.3104 - acc: 0.8961 - val_loss: 0.2705 - val_acc: 0.9042\n",
            "Epoch 4/50\n",
            "48000/48000 [==============================] - 18s 384us/step - loss: 0.2740 - acc: 0.9073 - val_loss: 0.2525 - val_acc: 0.9105\n",
            "Epoch 5/50\n",
            "48000/48000 [==============================] - 18s 384us/step - loss: 0.2505 - acc: 0.9159 - val_loss: 0.2434 - val_acc: 0.9118\n",
            "Epoch 6/50\n",
            "48000/48000 [==============================] - 18s 384us/step - loss: 0.2242 - acc: 0.9233 - val_loss: 0.2331 - val_acc: 0.9206\n",
            "Epoch 7/50\n",
            "48000/48000 [==============================] - 18s 384us/step - loss: 0.2112 - acc: 0.9289 - val_loss: 0.2275 - val_acc: 0.9234\n",
            "Epoch 8/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.1937 - acc: 0.9357 - val_loss: 0.2274 - val_acc: 0.9213\n",
            "Epoch 9/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.1783 - acc: 0.9413 - val_loss: 0.2235 - val_acc: 0.9237\n",
            "Epoch 10/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.1652 - acc: 0.9444 - val_loss: 0.2247 - val_acc: 0.9241\n",
            "Epoch 11/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.1531 - acc: 0.9501 - val_loss: 0.2222 - val_acc: 0.9258\n",
            "Epoch 12/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.1425 - acc: 0.9534 - val_loss: 0.2216 - val_acc: 0.9267\n",
            "Epoch 13/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.1327 - acc: 0.9559 - val_loss: 0.2213 - val_acc: 0.9275\n",
            "Epoch 14/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.1211 - acc: 0.9612 - val_loss: 0.2201 - val_acc: 0.9270\n",
            "Epoch 15/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.1141 - acc: 0.9624 - val_loss: 0.2279 - val_acc: 0.9293\n",
            "Epoch 16/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.1073 - acc: 0.9661 - val_loss: 0.2331 - val_acc: 0.9275\n",
            "Epoch 17/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.1010 - acc: 0.9688 - val_loss: 0.2378 - val_acc: 0.9296\n",
            "Epoch 18/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.0933 - acc: 0.9706 - val_loss: 0.2341 - val_acc: 0.9287\n",
            "Epoch 19/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.0858 - acc: 0.9746 - val_loss: 0.2404 - val_acc: 0.9298\n",
            "Epoch 20/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.0830 - acc: 0.9749 - val_loss: 0.2409 - val_acc: 0.9311\n",
            "Epoch 21/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.0789 - acc: 0.9762 - val_loss: 0.2490 - val_acc: 0.9295\n",
            "Epoch 22/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0731 - acc: 0.9785 - val_loss: 0.2619 - val_acc: 0.9303\n",
            "Epoch 23/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.0698 - acc: 0.9798 - val_loss: 0.2551 - val_acc: 0.9308\n",
            "Epoch 24/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0636 - acc: 0.9819 - val_loss: 0.2674 - val_acc: 0.9310\n",
            "Epoch 25/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.0608 - acc: 0.9827 - val_loss: 0.2683 - val_acc: 0.9303\n",
            "Epoch 26/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0585 - acc: 0.9838 - val_loss: 0.2743 - val_acc: 0.9311\n",
            "Epoch 27/50\n",
            "48000/48000 [==============================] - 18s 383us/step - loss: 0.0542 - acc: 0.9855 - val_loss: 0.2752 - val_acc: 0.9307\n",
            "Epoch 28/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0529 - acc: 0.9866 - val_loss: 0.2777 - val_acc: 0.9298\n",
            "Epoch 29/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0513 - acc: 0.9868 - val_loss: 0.2869 - val_acc: 0.9318\n",
            "Epoch 30/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0491 - acc: 0.9871 - val_loss: 0.2817 - val_acc: 0.9293\n",
            "Epoch 31/50\n",
            "48000/48000 [==============================] - 18s 382us/step - loss: 0.0462 - acc: 0.9882 - val_loss: 0.3010 - val_acc: 0.9282\n",
            "Epoch 32/50\n",
            "48000/48000 [==============================] - 18s 380us/step - loss: 0.0459 - acc: 0.9884 - val_loss: 0.2922 - val_acc: 0.9302\n",
            "Epoch 33/50\n",
            "48000/48000 [==============================] - 18s 380us/step - loss: 0.0414 - acc: 0.9904 - val_loss: 0.3082 - val_acc: 0.9311\n",
            "Epoch 34/50\n",
            "48000/48000 [==============================] - 18s 380us/step - loss: 0.0420 - acc: 0.9898 - val_loss: 0.2972 - val_acc: 0.9315\n",
            "Epoch 35/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0382 - acc: 0.9911 - val_loss: 0.3057 - val_acc: 0.9314\n",
            "Epoch 36/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0366 - acc: 0.9919 - val_loss: 0.3129 - val_acc: 0.9312\n",
            "Epoch 37/50\n",
            "48000/48000 [==============================] - 18s 379us/step - loss: 0.0373 - acc: 0.9914 - val_loss: 0.2975 - val_acc: 0.9335\n",
            "Epoch 38/50\n",
            "48000/48000 [==============================] - 18s 380us/step - loss: 0.0345 - acc: 0.9927 - val_loss: 0.3194 - val_acc: 0.9328\n",
            "Epoch 39/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0335 - acc: 0.9928 - val_loss: 0.3071 - val_acc: 0.9322\n",
            "Epoch 40/50\n",
            "48000/48000 [==============================] - 18s 379us/step - loss: 0.0334 - acc: 0.9931 - val_loss: 0.3296 - val_acc: 0.9308\n",
            "Epoch 41/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0329 - acc: 0.9932 - val_loss: 0.3228 - val_acc: 0.9318\n",
            "Epoch 42/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0321 - acc: 0.9934 - val_loss: 0.3240 - val_acc: 0.9328\n",
            "Epoch 43/50\n",
            "48000/48000 [==============================] - 18s 380us/step - loss: 0.0297 - acc: 0.9941 - val_loss: 0.3363 - val_acc: 0.9328\n",
            "Epoch 44/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0295 - acc: 0.9944 - val_loss: 0.3397 - val_acc: 0.9326\n",
            "Epoch 45/50\n",
            "48000/48000 [==============================] - 18s 381us/step - loss: 0.0282 - acc: 0.9948 - val_loss: 0.3360 - val_acc: 0.9325\n",
            "Epoch 46/50\n",
            "48000/48000 [==============================] - 18s 380us/step - loss: 0.0291 - acc: 0.9943 - val_loss: 0.3337 - val_acc: 0.9335\n",
            "Epoch 47/50\n",
            "48000/48000 [==============================] - 18s 379us/step - loss: 0.0277 - acc: 0.9955 - val_loss: 0.3390 - val_acc: 0.9327\n",
            "Epoch 48/50\n",
            "48000/48000 [==============================] - 18s 380us/step - loss: 0.0260 - acc: 0.9956 - val_loss: 0.3394 - val_acc: 0.9326\n",
            "Epoch 49/50\n",
            "48000/48000 [==============================] - 18s 379us/step - loss: 0.0253 - acc: 0.9958 - val_loss: 0.3555 - val_acc: 0.9317\n",
            "Epoch 50/50\n",
            "48000/48000 [==============================] - 18s 379us/step - loss: 0.0253 - acc: 0.9957 - val_loss: 0.3480 - val_acc: 0.9328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8dbbb774a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "0NkUn7nn16EI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3e3537a-184e-46b8-a88a-d97c8aa6c09e"
      },
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 141us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O3fm-hm_5BPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73fda761-dfd4-4e84-9f52-d8c046980720"
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \" + str(accuracy*100) + \"%\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 93.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B0XZ5VFLERvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}